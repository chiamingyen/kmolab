Title: Genetic Algorithm in Python
Category: Python
Tags: GA, 基因演算
Author: kmol

利用 Python 實現基因演算

<!-- PELICAN_END_SUMMARY -->

利用"Genetic Algorithm in python jupyter" 查詢, 得到如下的相關連結:

1. <https://github.com/DEAP/deap>, <a href="https://pypi.python.org/pypi/deap">Deap 1.0.2</a>
2. <a href="http://jupyter.cs.brynmawr.edu/hub/dblank/public/CS110%20Intro%20to%20Computing/2015/Lectures/Genetic%20Algorithm.ipynb">Genetic Algorithm notebook</a>
3. <a href="http://gitxiv.com/posts/4wYYffue4WfnhKZoB/book-kalman-and-bayesian-filters-in-python">Kalman and Bayesian Filters in Python</a>
4. <a href="https://lmarti.github.io/evolutionary-computation-course/AEC.02%20-%20Elements%20of%20Evolutionary%20Algorithms.slides.html#/">Elements of Evoluationary Algorithms</a>, related <a href="https://github.com/lmarti/evolutionary-computation-course">Course</a>, <a href="http://lmarti.github.io/evolutionary-computation-course/">Evolutionary Computation with IPython</a>
5. <https://github.com/jakevdp/JSAnimation>
6. <https://github.com/garethflowers/vscode-portable>
7. <https://github.com/dmahugh/crawlerino>
8. <http://paraschopra.com/sourcecode/GP/>
9. <https://github.com/cpmech/CIVL4250py/tree/master/2015>
10. <https://github.com/remiomosowon/pyeasyga>
11. <https://github.com/yati-sagade/Genetic-Algorithm-Demo>

開始: <http://lethain.com/genetic-algorithms-cool-name-damn-simple/>, trying to create a list of N numbers that equal X when summed together.

Each suggested solution for a genetic algorithm is referred to as an individual. In our current problem, each list of N numbers is an individual.

~~~python
from random import randint
def individual(length, min, max):
    'Create a member of the population.'
    return [ randint(min,max) for x in range(length) ]
'''
individual(5,0,100)
[79, 0, 20, 47, 40]
individual(5,0,100)
[64, 1, 25, 84, 87]
'''
~~~
<br />
The collection of all individuals is referred to as our population.

~~~python
def population(count, length, min, max):
    """
    Create a number of individuals (i.e. a population).
    
    count: the number of individuals in the population
    length: the number of values per individual
    min: the min possible value in an individual's list of values
     max: the max possible value in an individual's list of values
    """
    return [ individual(length, min, max) for x in range(count) ]
'''
population(3,5,0,100)
[[51, 55, 73, 0, 80], [3, 47, 18, 65, 55], [17, 64, 77, 43, 48]]
'''
~~~
<br />
Next we need a way to judge the how effective each solution is; to judge the fitness of each individual. Predictably enough, we call this the fitness function. For our problem, we want the fitness to be a function of the distance between the sum of an individuals numbers and the target number X.

We can implement the fitness function as follows:

~~~python
from operator import add
def fitness(individual, target):
    """
    Determine the fitness of an individual. Lower is better.
    
    individual: the individual to evaluate
    target: the sum of numbers that individuals are aiming for
    """
    sum = reduce(add, individual, 0)
    return abs(target-sum)
'''
x = individual(5,0,100)
fitness(x, 200)
165
'''
~~~
<br />
Personally, I'd prefer to have a high fitness score correlate to a fit individual rather than the current implementation where a perfectly fit individual has a fitness of 0, and the higher the worse. Ah well, regardless, keep that detail in mind while following this code.http://paraschopra.com/sourcecode/GP/index.php

It's also helpful to create a function that will determine a population's average fitness.
~~~python
def grade(pop, target):
    'Find average fitness for a population.'
    summed = reduce(add, (fitness(x, target) for x in pop), 0)
    return summed / (len(pop) * 1.0)
'''
x = population(3,5,0,100)
target = 200
grade(x, target)
116
'''
~~~
<br />
Now we just need a way evolve our population; to advance the population from one generation to the next.

Evolution
This is the secret sauce of genetic algorithms, where secret means fairly obvious, and sauce means sauce. Consider a population of elk which are ruthlessly hunted by a pack of wolves. With each generation the weakest are eaten by the wolves, and then the strongest elk reproduce and have children. Abstract those ideas a bit, and we can implement the evolution mechanism.

1. For each generation we'll take a portion of the best performing individuals as judged by our fitness function. These high-performers will be the parents of the next generation.

We'll also randomly select some lesser performing individuals to be parents, because we want to promote genetic diversity. Abandoning the metaphor, one of the dangers of optimization algorithms is getting stuck at a local maximum and consequently being unable to find the real maximum. By including some individuals who are not performing as well, we decrease our likelihood of getting stuck.

2. Breed together parents to repopulate the population to its desired size (if you take the top 20 individuals in a population of 100, then you'd need to create 80 new children via breeding). In our case, breeding is pretty basic: take the first N/2 digits from the father and the last N/2 digits from the mother.

~~~python
father = [1,2,3,4,5,6]
mother = [10,20,30,40,50,60]
child = father[:3] + mother[3:]
print(child)
'''
[1,2,3,40,50,60]
'''
~~~
<br />

It's okay to have one parent breed multiple times, but one parent should never be both the father and mother of a child.

3. Merge together the parents and children to constitute the next generation's population.

4. Finally we mutate a small random portion of the population. What this means is to have a probability of randomly modifying each individual.

~~~python
from random import random, randint
chance_to_mutate = 0.01
for i in population:
    if chance_to_mutate > random():
        place_to_modify = randint(0,len(i))
        i[place_to_modify] = randint(min(i), max(i))
~~~
<br />
This--just like taking individuals who are not performing particularly well--is to encourage genetic diversity, i.e. avoid getting stuck at local maxima.

Putting it all together, the code to evolve a generation can be implemented like this:

~~~python
def evolve(pop, target, retain=0.2, random_select=0.05, mutate=0.01):
    graded = [ (fitness(x, target), x) for x in pop]
    graded = [ x[1] for x in sorted(graded)]
    retain_length = int(len(graded)*retain)
    parents = graded[:retain_length]

    # randomly add other individuals to promote genetic diversity
    for individual in graded[retain_length:]:
        if random_select > random():
            parents.append(individual)

    # mutate some individuals
    for individual in parents:
        if mutate > random():
            pos_to_mutate = randint(0, len(individual)-1)
            # this mutation is not ideal, because it
            # restricts the range of possible values,
            # but the function is unaware of the min/max
            # values used to create the individuals,
            individual[pos_to_mutate] = randint(
                min(individual), max(individual))

    # crossover parents to create children
    parents_length = len(parents)
    desired_length = len(pop) - parents_length
    children = []
    while len(children) < desired_length:
        male = randint(0, parents_length-1)
        female = randint(0, parents_length-1)
        if male != female:
            male = parents[male]
            female = parents[female]
            half = len(male) / 2
            child = male[:half] + female[half:]
            children.append(child)

    parents.extend(children)
    return parents
~~~
<br />
Now we've written all the pieces of a genetic algorithm, and we just have to try it out and see if it works.

Testing It Out

Here is a simple way to use the code we've written:

~~~python
target = 371
p_count = 100
i_length = 5
i_min = 0
i_max = 100
p = population(p_count, i_length, i_min, i_max)
fitness_history = [grade(p, target),]
for i in range(100):
    p = evolve(p, target)
    fitness_history.append(grade(p, target))
for datum in fitness_history:
    print(datum)
~~~
<br />
Running that code, you'll get to watch as generations' fitness gradually (but non-deterministically) approach zero. The output of one of my runs looked like this:

With 20% survival (plus an additional 5% of other individuals) and 1% mutation, it only took nine generations to reach a perfect solution. Then the algorithm joyfully runs in circles for as long as you'll let the mutations continue But this is a good feeling right? If it only took us half an hour to solve a problem of this magnitude, imagine what we could do with a day. A genetic algorithm for optimizing your Apache2 configuration file for number of children processes? Easy as pie.

There are a nearly endless variety of techniques for and variations of genetic algorithms, but all of them rest on this straight forward foundation. We'll look more at those sometime in the future, but for now you know enough to go out and throw together something interesting.

~~~python
"""
# Example usage
from genetic import *
target = 371
p_count = 100
i_length = 6
i_min = 0
i_max = 100
p = population(p_count, i_length, i_min, i_max)
fitness_history = [grade(p, target),]
for i in range(100):
    p = evolve(p, target)
    fitness_history.append(grade(p, target))

for datum in fitness_history:
   print(datum)
"""
from random import randint, random
from operator import add

def individual(length, min, max):
    'Create a member of the population.'
    return [ randint(min,max) for x in range(length) ]

def population(count, length, min, max):
    """
    Create a number of individuals (i.e. a population).

    count: the number of individuals in the population
    length: the number of values per individual
    min: the minimum possible value in an individual's list of values
    max: the maximum possible value in an individual's list of values

    """
    return [ individual(length, min, max) for x in xrange(count) ]

def fitness(individual, target):
    """
    Determine the fitness of an individual. Higher is better.

    individual: the individual to evaluate
    target: the target number individuals are aiming for
    """
    sum = reduce(add, individual, 0)
    return abs(target-sum)

def grade(pop, target):
    'Find average fitness for a population.'
    summed = reduce(add, (fitness(x, target) for x in pop))
    return summed / (len(pop) * 1.0)

def evolve(pop, target, retain=0.2, random_select=0.05, mutate=0.01):
    graded = [ (fitness(x, target), x) for x in pop]
    graded = [ x[1] for x in sorted(graded)]
    retain_length = int(len(graded)*retain)
    parents = graded[:retain_length]
    # randomly add other individuals to
    # promote genetic diversity
    for individual in graded[retain_length:]:
        if random_select > random():
            parents.append(individual)
    # mutate some individuals
    for individual in parents:
        if mutate > random():
            pos_to_mutate = randint(0, len(individual)-1)
            # this mutation is not ideal, because it
            # restricts the range of possible values,
            # but the function is unaware of the min/max
            # values used to create the individuals,
            individual[pos_to_mutate] = randint(
                min(individual), max(individual))
    # crossover parents to create children
    parents_length = len(parents)
    desired_length = len(pop) - parents_length
    children = []
    while len(children) < desired_length:
        male = randint(0, parents_length-1)
        female = randint(0, parents_length-1)
        if male != female:
            male = parents[male]
            female = parents[female]
            half = len(male) / 2
            child = male[:half] + female[half:]
            children.append(child)
    parents.extend(children)
    return parents
~~~
<br />

# 在 Ubuntu 安裝 numpy 與 scipy for python3, 但 scipy 無法運作
# sudo apt-get install python3-numpy python3-scipy
# 必須先安裝下列程式庫
# install python development packages and g++
# apt-get install -y python3-dev g++
# install dependencies for scipy
# apt-get install -y libblas-dev liblapack-dev gfortran
# 然後再 sudo -H pip3 install scipy

以下則為 binary coded Genetic Algorithm in Python3:

~~~python
#encoding=utf8
# genetic.py
#
import random
import operator
# for Intersect
from math import *
MAXIMIZE, MINIMIZE = 11, 22
class Individual:
    # 染色體先設為 None
    chromosome = None
    # 得分也先設為 None
    score = None
    # Here the size of var depends on var_number print
    # var 變數的元素個數取決於 var_number 的個數 (即變數個數)
    var = []
    # 表示適應值變數個數有兩個
    var_number = 2
    #先將 var 數列中元素都設為 0
    for i in range(var_number):
        var.append(0)
    # 等位基因表示各基因可選的內容, 這裡表示不是 0 就是 1
    alleles = (0,1)
    # 2**10 = 32*32 = 1024, 表示若用十個 binary 位數來表示整數, 可以表示從 0 到 1023 的數值大小
    # 若也用另外 十個 binary 位數來表示小數值, 則也是 0 到 1023 的數值表示能力, 
    # 而再加一個表示正負的代表 binary 位數, 每一個變數需要 21 個 binary numbers 
    # 以下為參數可負數時的編碼考量
    #前10為小數,後10為整數,第21則為正負號
    #0~9表示小數,10~19表示整數,而指標第20則表示第一數的正號或負號,若為0則表示正,若為1表示負號.
    #21~30表示第二數的小數部分,31~40則表示第二數的整數部分,第41指標則表示第二數的正號或負號
    #42~51表示第三數的小數部分,52~61則表示第二數的整數部分,第62指標則表示第三數的正號或負號
    # -1023 ~ 1023
    #length = 21*var_number,若接受負數參數,則必須同步修改 20->21
    # 因為這裡只接受正的變數值, 所以每一個變數需要 20 個 binary 位數
    length = 20*var_number
    seperator = ''
    optimization = MINIMIZE
    
    def __init__(self, chromosome=None):
        self.chromosome = chromosome or self._makechromosome()
        self.score = None  # set during evaluation

    '''
    bitwise operators (binary left shift): The left operands value is moved left by the number of bits specified by the right operand.
    x << y
    Returns x with the bits shifted to the left by y places (and new bits on the right-hand-side are zeros). This is the same as multiplying x by 2**y.
    '''
    # 根據染色體各位元的值轉為 10 進位值
    def _getvar(self, chromosome=None):
        # x 起始值設為 0
        x = 0
        for i in range(0, self.var_number):
            # 先根據前 20 個位元值, 透過 binary left shift 轉為 10 進位之後, 再轉為對應小數
            for j in range(i*20, i*20+10):
                x += self.chromosome[j]<<(j-(i*20))
            # 因為前 20 個 binary 數, 負責 10 進位數的小數點後 3 個位數, 只要轉為 10 進位值之後, 若大於 999, 則僅取 999,
            # 再除以 1000, 可以得到 .999 表示 .999 為最大的小數表示數, 不要因為大於 1000 後若除以 1000 將進位到整數, 會與整數有交互影響
            if (x>999):
                x = 999
            x /= 1000.
            # 整數部份 0 ~ 1023 的表示範圍則沒有問題, 利用 bitwise 轉換後, 直接取整數值
            for j in range(i*20+10, i*20+20):
                x += self.chromosome[j]<<(j-(i*20+10))
            self.var[i] = x
        return self.var

    ''' for -1023 ~ 1023,當設計變數可以接受負值時使用,每一變數使用21個 bit strings
    #for design variable -1023 ~1023
        for i in range(self.var_number):
            x = 0
            for j in range(i*21, i*21+10):
                x += self.chromosome[j]<<(j-(i*21))
            if (x>999):
                x = 999
            x /= 1000.
            for j in range(i*(21)+10, i*(21)+20):
                x += self.chromosome[j]<<(j-(i*21+10))
            # 各變數範圍第 21 位數若為 1, 則表示該數為負數
            if(self.chromosome[i*(21)+20] == 1):
                self.var[i] = -x
            else:
                self.var[i] = x
            # 讓 x 再設回原值 0 表示內定各變數為正數
            x = 0
        return self.var
    '''
    # 建立染色體
    def _makechromosome(self):
        "makes a chromosome from randomly selected alleles."
        return [random.choice(self.alleles) for gene in range(self.length)]

    # 計算適應值
    def evaluate(self, optimum=None):
        "this method MUST be overridden to evaluate individual fitness score."
        pass

    # 交配方法
    def crossover(self, other):
        "override this method to use your preferred crossover method."
        return self._twopoint(other)

    # 突變方法
    def mutate(self, gene):
        "override this method to use your preferred mutation method."
        self._pick(gene)

    # sample mutation method
    def _pick(self, gene):
        "chooses a random allele to replace this gene's allele."
        self.chromosome[gene] = random.choice(self.alleles)

    # sample crossover method
    def _twopoint(self, other):
        "creates offspring via two-point crossover between mates."
        left, right = self._pickpivots()
        
        def mate(p0, p1):
            chromosome = p0.chromosome[:] # 交配時,以p0的基因為基礎(複製整個 p0 的染色體內容
            chromosome[left:right] = p1.chromosome[left:right] # 接續上一個 p0 的染色體內容,將索引 left 至 right 的內容,替換成 p1 的基因
            child = p0.__class__(chromosome)
            child._repair(p0, p1)
            return child
        return mate(self, other), mate(other, self)

    # some crossover helpers ...
    def _repair(self, parent1, parent2):
        "override this method, if necessary, to fix duplicated genes."
        pass

    def _pickpivots(self):
        left = random.randrange(1, self.length-2)
        right = random.randrange(left, self.length-1)
        return left, right
    #
    # other methods
    #
    def __repr__(self):
        "returns string representation of self"
        '''
        return '<%s chromosome="%s" score=%s var=%s>' % \
               (self.__class__.__name__,
                self.seperator.join(map(str,self.chromosome)), self.score,self._getvar(self.chromosome))
        '''
        return '<%s score=%s var=%s>' % \
               (self.__class__.__name__,self.score,self._getvar(self.chromosome))
    # since the __cmp__ special function is gone  use the __lt__ in stead
    # use the expression (a > b) - (a < b) as the equivalent for cmp(a, b)
    #def __cmp__(self, other):
    # these are for python 3
    def __cmp__(self, other):
        if self.optimization == MINIMIZE:
            #return cmp(self.score, other.score)
            return (self.score > other.score) - (self.score < other.score)
        else: # MAXIMIZE
            #return cmp(other.score, self.score)
            return (other.score > self.score) - (other.score < self.score)
            
    def __lt__(self, other):
        return self.__cmp__(other) < 0
    def __le__(self, other):
        return self.__cmp__(other) <= 0
    def __gt__(self, other):
        return self.__cmp__(other) > 0
    def __ge__(self, other):
        return self.__cmp__(other) >= 0 
    def copy(self):
        twin = self.__class__(self.chromosome[:])
        twin.score = self.score
        return twin
class Environment(object):
    x = [0]
    y = [0]

    def __init__(self, kind, population=None, size=100, maxgenerations=100,
                 crossover_rate=0.90, mutation_rate=0.07, optimum=None):
        self.kind = kind
        self.size = size
        self.optimum = optimum
        self.population = population or self._makepopulation()
        for individual in self.population:
            individual.evaluate(self.optimum)
        self.crossover_rate = crossover_rate
        self.mutation_rate = mutation_rate
        self.maxgenerations = maxgenerations
        self.generation = 0
        self.report()

    def _makepopulation(self):
        return [self.kind() for individual in range(self.size)]

    def run(self):
        while not self._goal():
            self.step()

    def _goal(self):
        return self.generation > self.maxgenerations or \
               self.best.score == self.optimum

    def step(self):
        # this sort is not working with python 3.0, modification is needed
        self.population.sort()
        self._crossover()
        self.generation += 1
        self.report()
        self.x.append(self.generation)
        # 設定為只附加所選定範圍的值,這裡只取大於或等於 0 的 score 值
        if self.best.score <=5:
            self.y.append(self.best.score)
        else:
            self.y.append(5)

    def _crossover(self):
        next_population = [self.best.copy()]
        while len(next_population) < self.size:
            mate1 = self._select()
            if random.random() < self.crossover_rate:
                mate2 = self._select()
                offspring = mate1.crossover(mate2)
            else:
                offspring = [mate1.copy()]
            for individual in offspring:
                self._mutate(individual)
                individual.evaluate(self.optimum)
                next_population.append(individual)
        self.population = next_population[:self.size]

    def _select(self):
        "override this to use your preferred selection method"
        return self._tournament()

    def _mutate(self, individual):
        for gene in range(individual.length):
            if random.random() < self.mutation_rate:
                individual.mutate(gene)
    #
    # sample selection method
    #
    def _tournament(self, size=8, choosebest=0.90):
        competitors = [random.choice(self.population) for i in range(size)]
        competitors.sort()
        if random.random() < choosebest:
            return competitors[0]
        else:
            return random.choice(competitors[1:])

    def best():
        doc = "individual with best fitness score in population."
        def fget(self):
            return self.population[0]
        return locals()
    best = property(**best())

    def report(self):
        '''
        print ("="*70)
        print ("generation: ", self.generation)
        print ("best:       ", self.best)
        '''
        g.es ("="*70)
        g.es ("generation: ", self.generation)
        g.es ("best:       ", self.best)
        
# 以上為 genetic.py 目前將兩者結合在一起
#encoding=utf8
# volume.py - useage example
#
# the fittest individual will have a chromosome consisting of 40 '1's
#
#
#import genetic
class Volume(Individual):
    optimization = MAXIMIZE
    def evaluate(self, optimum=None):
        SURFACE = 80
        # self.score is the fitness value
        self._getvar(self.chromosome)
        
        x = self.var[0]
        y = self.var[1]
        z=(SURFACE - x*y)/(2.*(x+y))
        fitness_value = x*y*z
        
        self.score = fitness_value
        
    def mutate(self, gene):
        self.chromosome[gene] = not self.chromosome[gene] # bit flip

class Intersect(Individual):
    optimization = MINIMIZE
    def evaluate(self, optimum=None):
        # self.score is the fitness value
        self._getvar(self.chromosome)
        
        t = self.var[0]
        deg = pi/180
        theta = self.var[1]*deg
        xtarget = 0.75/2
        ytarget = 0.5
        x = t*sqrt(-225*sin(theta)**2 + 529)/10 - sqrt(-225*sin(theta)**2 + 529)/92 + 3*cos(theta)/2
        y = (-3*t/2 + 123/92)*sin(theta)
        # 適應值
        fitness_value = pow(x-xtarget, 8)+pow(y-ytarget, 8)

        # 指定 t 的範圍, 小於 1 大於 0, 否則給予處罰
        if t > 1:
            fitness_value += 1000
        if t < 0:
            fitness_value += 1000
        # 指定 theta 的範圍, 小於 2pi 大於 0, 否則給予處罰
        if theta > 2*pi:
            fitness_value += 1000
        if theta < 0:
            fitness_value += 1000

        
        self.score = fitness_value
        
    def mutate(self, gene):
        self.chromosome[gene] = not self.chromosome[gene] # bit flip
        

if __name__ == "__main__":
    #env = Environment(Volume, size=500, maxgenerations=100)
    env = Environment(Intersect, size=500, maxgenerations=100)
    env.run()
~~~
<br />
~~~python